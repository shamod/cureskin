{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAM10000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O74-OI47pSaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np \n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import tensorflow as tf\n",
        " \n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        " \n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "img = []\n",
        "image_path=\"/content/drive/My Drive/kaggle/cancer/train/HAM10000_images_part_2/ISIC_0029310.jpg\"\n",
        "img = cv2.imread(image_path)       \n",
        "print(img.shape)\n",
        "imCopy = img.copy()\n",
        "imgOut = cv2.resize(imCopy,(135,180))\n",
        "print(imgOut.shape)\n",
        "cv2_imshow(imgOut)\n",
        "#status = cv2.imwrite('drive/My Drive/imgOut/processed{:>02}.png'.format(), imgOut)\n",
        "#            i += 1\n",
        "\n",
        "\n",
        "#IMG_SIZE = 180 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGl-IMW6OHBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGv0lj2DOG8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy6c3n0v9iwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f7537127-daca-4da1-ea61-8208bb7daafa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WAIezV_Loz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTYC2a-B_NDW",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "eea0fe40-7d47-46c7-90e2-563073e5c42e"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()  #this will prompt you to upload the kaggle.json"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-50689fa7-e28e-4c35-90dc-3654667c4f00\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-50689fa7-e28e-4c35-90dc-3654667c4f00\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"haggishm\",\"key\":\"304163c8690c1a17665877cc38155e81\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EHZSjTg_NGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "954b4895-7551-43ac-a533-1670fc0d221c"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKfBkO2GAOHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c4f2d1e1-aee6-46e7-fb39-e0c4da6312a5"
      },
      "source": [
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000 -p /content/drive/My\\ Drive/kaggle/cancer\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading skin-cancer-mnist-ham10000.zip to /content/drive/My Drive/kaggle/cancer\n",
            "100% 5.19G/5.20G [00:55<00:00, 84.4MB/s]\n",
            "100% 5.20G/5.20G [00:55<00:00, 101MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ricg2JGnB4ZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/kaggle/cancer')  #change dir\n",
        "#!mkdir train  #create a directory named train/\n",
        "#!mkdir test  #create a directory named test/\n",
        "!unzip -q skin-cancer-mnist-ham10000.zip   #unzip data in train/\n",
        "#!unzip -q test.zip -d test/  #unzip data in test/\n",
        "#!unzip sample_submission.csv.zip\n",
        "#!unzip train_labels.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0UjN_rCHwE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALq7b4IlHwRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "5d4d4654-d2df-462b-e959-7fd43bcf7fd3"
      },
      "source": [
        "# Skin Cancer Dataset Preprocessing\n",
        "\n",
        "# Import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "# Create a new directory for the images\n",
        "base_dir = 'base_dir'\n",
        "#os.mkdir(base_dir)\n",
        "\n",
        "# Training file directory\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "#os.mkdir(train_dir)\n",
        "\n",
        "# Validation file directory\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "#os.mkdir(val_dir)\n",
        "\n",
        "# Create new folders in the training directory for each of the classes\n",
        "nv = os.path.join(train_dir, 'nv')\n",
        "#os.mkdir(nv)\n",
        "mel = os.path.join(train_dir, 'mel')\n",
        "#os.mkdir(mel)\n",
        "bkl = os.path.join(train_dir, 'bkl')\n",
        "#os.mkdir(bkl)\n",
        "bcc = os.path.join(train_dir, 'bcc')\n",
        "#os.mkdir(bcc)\n",
        "akiec = os.path.join(train_dir, 'akiec')\n",
        "#os.mkdir(akiec)\n",
        "vasc = os.path.join(train_dir, 'vasc')\n",
        "#os.mkdir(vasc)\n",
        "df = os.path.join(train_dir, 'df')\n",
        "#os.mkdir(df)\n",
        "\n",
        "# Create new folders in the validation directory for each of the classes\n",
        "nv = os.path.join(val_dir, 'nv')\n",
        "#os.mkdir(nv)\n",
        "mel = os.path.join(val_dir, 'mel')\n",
        "#os.mkdir(mel)\n",
        "bkl = os.path.join(val_dir, 'bkl')\n",
        "#os.mkdir(bkl)\n",
        "bcc = os.path.join(val_dir, 'bcc')\n",
        "#os.mkdir(bcc)\n",
        "akiec = os.path.join(val_dir, 'akiec')\n",
        "#os.mkdir(akiec)\n",
        "vasc = os.path.join(val_dir, 'vasc')\n",
        "#os.mkdir(vasc)\n",
        "df = os.path.join(val_dir, 'df')\n",
        "#os.mkdir(df)\n",
        "\n",
        "# Read the metadata\n",
        "df = pd.read_csv('/content/drive/My Drive/kaggle/cancer/base_dir/HAM10000_metadata.csv')\n",
        "\n",
        "# Display some information in the dataset\n",
        "df.head()\n",
        "\n",
        "# Set y as the labels\n",
        "y = df['dx']\n",
        "\n",
        "# Split the metadata into training and validation\n",
        "df_train, df_val = train_test_split(df, test_size=0.1, random_state=101, stratify=y)\n",
        "\n",
        "# Print the shape of the training and validation split\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)\n",
        "\n",
        "# Find the number of values in the training and validation set\n",
        "df_train['dx'].value_counts()\n",
        "df_val['dx'].value_counts()\n",
        "\n",
        "# Transfer the images into folders\n",
        "# Set the image id as the index\n",
        "df.set_index('image_id', inplace=True)\n",
        "\n",
        "# Get a list of images in each of the two folders\n",
        "folder_1 = os.listdir('/content/drive/My Drive/kaggle/cancer/base_dir/ham10000_images_part_1')\n",
        "folder_2 = os.listdir('/content/drive/My Drive/kaggle/cancer/base_dir/ham10000_images_part_2')\n",
        "\n",
        "# Get a list of train and val images\n",
        "train_list = list(df_train['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "# Transfer the training images\n",
        "for image in train_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df.loc[image, 'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/kaggle/cancer/base_dir/ham10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/kaggle/cancer/base_dir/ham10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Transfer the validation images\n",
        "for image in val_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df.loc[image, 'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/kaggle/cancer/base_dir/ham10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/kaggle/cancer/base_dir/ham10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Check how many training images are in each folder\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))\n",
        "\n",
        "# Check how many validation images are in each folder\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))\n",
        "\n",
        "# Augment the data\n",
        "# Class 'nv' is not going to be augmented\n",
        "class_list = ['mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
        "\n",
        "for item in class_list:\n",
        "\n",
        "    # Create a temporary directory for the augmented images\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "\n",
        "    # Create a directory within the base dir to store images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    # Choose a class\n",
        "    img_class = item\n",
        "\n",
        "    # List all the images in the directory\n",
        "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir\n",
        "    for fname in img_list:\n",
        "        # source path to image\n",
        "        src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(img_dir, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = 'base_dir/train_dir/' + img_class\n",
        "\n",
        "    # Create a data generator to augment the images in real time\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        # brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                              save_to_dir=save_path,\n",
        "                                              save_format='jpg',\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "    # Generate the augmented images and add them to the training folders\n",
        "    num_aug_images_wanted = 6000  # total number of images we want to have in each class\n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted - num_files) / batch_size))\n",
        "\n",
        "    # run the generator and create about 6000 augmented images\n",
        "    for i in range(0, num_batches):\n",
        "        imgs, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('aug_dir')\n",
        "\n",
        "# Check how many train images are each folder (original + augmented)\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))\n",
        "\n",
        "# Check how many validation images are in each folder\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9013, 7)\n",
            "(1002, 7)\n",
            "6034\n",
            "1002\n",
            "989\n",
            "463\n",
            "294\n",
            "128\n",
            "103\n",
            "671\n",
            "111\n",
            "110\n",
            "51\n",
            "33\n",
            "14\n",
            "12\n",
            "Found 1002 images belonging to 1 classes.\n",
            "Found 989 images belonging to 1 classes.\n",
            "Found 463 images belonging to 1 classes.\n",
            "Found 294 images belonging to 1 classes.\n",
            "Found 128 images belonging to 1 classes.\n",
            "Found 103 images belonging to 1 classes.\n",
            "6034\n",
            "5810\n",
            "5984\n",
            "5606\n",
            "5930\n",
            "5170\n",
            "4170\n",
            "671\n",
            "111\n",
            "110\n",
            "51\n",
            "33\n",
            "14\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRXhbp0EHwWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWiYyvlc9TGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d50e1cd9-5860-4a4a-a8fc-12dd25d7c8b9"
      },
      "source": [
        "# The model for the skin cancer classifier\n",
        "\n",
        "# Import the libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if GPU is available\n",
        "K.tensorflow_backend._get_available_gpus()\n",
        "\n",
        "# The paths for the training and validation images\n",
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "\n",
        "# Declare a few useful values\n",
        "num_train_samples = 9013\n",
        "num_val_samples = 1002\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "image_size = 224\n",
        "\n",
        "# Declare how many steps are needed in an iteration\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
        "\n",
        "# Set up generators\n",
        "train_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=train_batch_size)\n",
        "\n",
        "valid_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size)\n",
        "\n",
        "test_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Create a MobileNet model\n",
        "mobile = keras.applications.mobilenet.MobileNet()\n",
        "\n",
        "# See a summary of the layers in the model\n",
        "mobile.summary()\n",
        "\n",
        "# Modify the model\n",
        "# Exclude the last 5 layers of the model\n",
        "x = mobile.layers[-6].output\n",
        "# Add a dropout and dense layer for predictions\n",
        "x = Dropout(0.25)(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Create a new model with the new outputs\n",
        "model = Model(inputs=mobile.input, outputs=predictions)\n",
        "\n",
        "# See a summary of the new layers in the model\n",
        "model.summary()\n",
        "\n",
        "# Freeze the weights of the layers that we aren't training (training the last 23)\n",
        "for layer in model.layers[:-23]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Train the model\n",
        "# Define Top2 and Top3 Accuracy\n",
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
        "\n",
        "# Add weights to make the model more sensitive to melanoma\n",
        "class_weights={\n",
        "    0: 1.0,  # akiec\n",
        "    1: 1.0,  # bcc\n",
        "    2: 1.0,  # bkl\n",
        "    3: 1.0,  # df\n",
        "    4: 3.0,  # mel\n",
        "    5: 1.0,  # nv\n",
        "    6: 1.0,  # vasc\n",
        "}\n",
        "\n",
        "# Declare the filepath for the saved model\n",
        "filepath = \"model.h5\"\n",
        "\n",
        "# Declare a checkpoint to save the best version of the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "# Reduce the learning rate as the learning stagnates\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
        "                              verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              class_weight=class_weights,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=30,\n",
        "                              verbose=1,\n",
        "                              callbacks=callbacks_list)\n",
        "\n",
        "# Evaluate the model\n",
        "# Evaluation of the last epoch\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)\n",
        "\n",
        "# Evaluation of the best epoch\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)\n",
        "\n",
        "# Create a confusion matrix of the test images\n",
        "test_labels = test_batches.classes\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict_generator(test_batches, steps=val_steps, verbose=1)\n",
        "\n",
        "# Declare a function for plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
        "\n",
        "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Found 38704 images belonging to 7 classes.\n",
            "Found 1002 images belonging to 7 classes.\n",
            "Found 1002 images belonging to 7 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Model: \"mobilenet_1.00_224\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "act_softmax (Activation)     (None, 1000)              0         \n",
            "=================================================================\n",
            "Total params: 4,253,864\n",
            "Trainable params: 4,231,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 3,236,039\n",
            "Trainable params: 3,214,151\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/30\n",
            "902/902 [==============================] - 90s 99ms/step - loss: 1.7367 - categorical_accuracy: 0.5241 - top_2_accuracy: 0.7245 - top_3_accuracy: 0.8475 - val_loss: 2.4093 - val_categorical_accuracy: 0.4990 - val_top_2_accuracy: 0.7246 - val_top_3_accuracy: 0.8363\n",
            "\n",
            "Epoch 00001: val_top_3_accuracy improved from -inf to 0.83633, saving model to model.h5\n",
            "Epoch 2/30\n",
            "902/902 [==============================] - 83s 92ms/step - loss: 1.2635 - categorical_accuracy: 0.6086 - top_2_accuracy: 0.8078 - top_3_accuracy: 0.9136 - val_loss: 2.7085 - val_categorical_accuracy: 0.4311 - val_top_2_accuracy: 0.7914 - val_top_3_accuracy: 0.8493\n",
            "\n",
            "Epoch 00002: val_top_3_accuracy improved from 0.83633 to 0.84930, saving model to model.h5\n",
            "Epoch 3/30\n",
            "902/902 [==============================] - 86s 95ms/step - loss: 1.1185 - categorical_accuracy: 0.6572 - top_2_accuracy: 0.8442 - top_3_accuracy: 0.9334 - val_loss: 3.0854 - val_categorical_accuracy: 0.5080 - val_top_2_accuracy: 0.7854 - val_top_3_accuracy: 0.8713\n",
            "\n",
            "Epoch 00003: val_top_3_accuracy improved from 0.84930 to 0.87126, saving model to model.h5\n",
            "Epoch 4/30\n",
            "902/902 [==============================] - 88s 97ms/step - loss: 1.0698 - categorical_accuracy: 0.6755 - top_2_accuracy: 0.8598 - top_3_accuracy: 0.9442 - val_loss: 2.4999 - val_categorical_accuracy: 0.4820 - val_top_2_accuracy: 0.7375 - val_top_3_accuracy: 0.8393\n",
            "\n",
            "Epoch 00004: val_top_3_accuracy did not improve from 0.87126\n",
            "Epoch 5/30\n",
            "902/902 [==============================] - 81s 89ms/step - loss: 0.9893 - categorical_accuracy: 0.6931 - top_2_accuracy: 0.8718 - top_3_accuracy: 0.9540 - val_loss: 1.2832 - val_categorical_accuracy: 0.6138 - val_top_2_accuracy: 0.7924 - val_top_3_accuracy: 0.8932\n",
            "\n",
            "Epoch 00005: val_top_3_accuracy improved from 0.87126 to 0.89321, saving model to model.h5\n",
            "Epoch 6/30\n",
            "902/902 [==============================] - 77s 86ms/step - loss: 0.9642 - categorical_accuracy: 0.7063 - top_2_accuracy: 0.8785 - top_3_accuracy: 0.9563 - val_loss: 1.3409 - val_categorical_accuracy: 0.5020 - val_top_2_accuracy: 0.8244 - val_top_3_accuracy: 0.9222\n",
            "\n",
            "Epoch 00006: val_top_3_accuracy improved from 0.89321 to 0.92216, saving model to model.h5\n",
            "Epoch 7/30\n",
            "902/902 [==============================] - 78s 86ms/step - loss: 0.9113 - categorical_accuracy: 0.7118 - top_2_accuracy: 0.8891 - top_3_accuracy: 0.9588 - val_loss: 1.1870 - val_categorical_accuracy: 0.6397 - val_top_2_accuracy: 0.8184 - val_top_3_accuracy: 0.8892\n",
            "\n",
            "Epoch 00007: val_top_3_accuracy did not improve from 0.92216\n",
            "Epoch 8/30\n",
            "902/902 [==============================] - 76s 84ms/step - loss: 0.8812 - categorical_accuracy: 0.7273 - top_2_accuracy: 0.8948 - top_3_accuracy: 0.9645 - val_loss: 1.4576 - val_categorical_accuracy: 0.6178 - val_top_2_accuracy: 0.8134 - val_top_3_accuracy: 0.8952\n",
            "\n",
            "Epoch 00008: val_top_3_accuracy did not improve from 0.92216\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "Epoch 9/30\n",
            "902/902 [==============================] - 76s 84ms/step - loss: 0.7216 - categorical_accuracy: 0.7748 - top_2_accuracy: 0.9190 - top_3_accuracy: 0.9779 - val_loss: 0.8592 - val_categorical_accuracy: 0.7255 - val_top_2_accuracy: 0.8593 - val_top_3_accuracy: 0.9192\n",
            "\n",
            "Epoch 00009: val_top_3_accuracy did not improve from 0.92216\n",
            "Epoch 10/30\n",
            "902/902 [==============================] - 72s 80ms/step - loss: 0.6804 - categorical_accuracy: 0.7890 - top_2_accuracy: 0.9298 - top_3_accuracy: 0.9824 - val_loss: 0.9022 - val_categorical_accuracy: 0.6946 - val_top_2_accuracy: 0.8603 - val_top_3_accuracy: 0.9261\n",
            "\n",
            "Epoch 00010: val_top_3_accuracy improved from 0.92216 to 0.92615, saving model to model.h5\n",
            "Epoch 11/30\n",
            "902/902 [==============================] - 73s 81ms/step - loss: 0.6584 - categorical_accuracy: 0.7968 - top_2_accuracy: 0.9337 - top_3_accuracy: 0.9837 - val_loss: 1.1785 - val_categorical_accuracy: 0.6148 - val_top_2_accuracy: 0.8234 - val_top_3_accuracy: 0.8822\n",
            "\n",
            "Epoch 00011: val_top_3_accuracy did not improve from 0.92615\n",
            "Epoch 12/30\n",
            "902/902 [==============================] - 72s 80ms/step - loss: 0.6125 - categorical_accuracy: 0.8088 - top_2_accuracy: 0.9411 - top_3_accuracy: 0.9843 - val_loss: 1.1139 - val_categorical_accuracy: 0.6677 - val_top_2_accuracy: 0.8403 - val_top_3_accuracy: 0.9192\n",
            "\n",
            "Epoch 00012: val_top_3_accuracy did not improve from 0.92615\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "Epoch 13/30\n",
            "902/902 [==============================] - 72s 80ms/step - loss: 0.5581 - categorical_accuracy: 0.8231 - top_2_accuracy: 0.9483 - top_3_accuracy: 0.9865 - val_loss: 0.8525 - val_categorical_accuracy: 0.7186 - val_top_2_accuracy: 0.8683 - val_top_3_accuracy: 0.9261\n",
            "\n",
            "Epoch 00013: val_top_3_accuracy did not improve from 0.92615\n",
            "Epoch 14/30\n",
            "902/902 [==============================] - 72s 80ms/step - loss: 0.4633 - categorical_accuracy: 0.8600 - top_2_accuracy: 0.9661 - top_3_accuracy: 0.9932 - val_loss: 0.8391 - val_categorical_accuracy: 0.7246 - val_top_2_accuracy: 0.8713 - val_top_3_accuracy: 0.9471\n",
            "\n",
            "Epoch 00014: val_top_3_accuracy improved from 0.92615 to 0.94711, saving model to model.h5\n",
            "Epoch 15/30\n",
            "902/902 [==============================] - 74s 82ms/step - loss: 0.4792 - categorical_accuracy: 0.8502 - top_2_accuracy: 0.9624 - top_3_accuracy: 0.9908 - val_loss: 0.8822 - val_categorical_accuracy: 0.7136 - val_top_2_accuracy: 0.8603 - val_top_3_accuracy: 0.9381\n",
            "\n",
            "Epoch 00015: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 16/30\n",
            "902/902 [==============================] - 75s 83ms/step - loss: 0.4660 - categorical_accuracy: 0.8574 - top_2_accuracy: 0.9630 - top_3_accuracy: 0.9914 - val_loss: 1.0526 - val_categorical_accuracy: 0.6996 - val_top_2_accuracy: 0.8563 - val_top_3_accuracy: 0.9182\n",
            "\n",
            "Epoch 00016: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "Epoch 17/30\n",
            "902/902 [==============================] - 74s 82ms/step - loss: 0.4444 - categorical_accuracy: 0.8599 - top_2_accuracy: 0.9634 - top_3_accuracy: 0.9926 - val_loss: 0.8791 - val_categorical_accuracy: 0.7255 - val_top_2_accuracy: 0.8743 - val_top_3_accuracy: 0.9261\n",
            "\n",
            "Epoch 00017: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 18/30\n",
            "902/902 [==============================] - 72s 80ms/step - loss: 0.3928 - categorical_accuracy: 0.8774 - top_2_accuracy: 0.9723 - top_3_accuracy: 0.9945 - val_loss: 0.8444 - val_categorical_accuracy: 0.7166 - val_top_2_accuracy: 0.8812 - val_top_3_accuracy: 0.9361\n",
            "\n",
            "Epoch 00018: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "Epoch 19/30\n",
            "902/902 [==============================] - 72s 79ms/step - loss: 0.3512 - categorical_accuracy: 0.8881 - top_2_accuracy: 0.9749 - top_3_accuracy: 0.9959 - val_loss: 0.9223 - val_categorical_accuracy: 0.7046 - val_top_2_accuracy: 0.8713 - val_top_3_accuracy: 0.9341\n",
            "\n",
            "Epoch 00019: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 20/30\n",
            "902/902 [==============================] - 73s 81ms/step - loss: 0.3528 - categorical_accuracy: 0.8882 - top_2_accuracy: 0.9764 - top_3_accuracy: 0.9962 - val_loss: 0.9377 - val_categorical_accuracy: 0.6996 - val_top_2_accuracy: 0.8733 - val_top_3_accuracy: 0.9351\n",
            "\n",
            "Epoch 00020: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "Epoch 21/30\n",
            "902/902 [==============================] - 71s 79ms/step - loss: 0.3388 - categorical_accuracy: 0.8902 - top_2_accuracy: 0.9779 - top_3_accuracy: 0.9972 - val_loss: 0.8967 - val_categorical_accuracy: 0.7335 - val_top_2_accuracy: 0.8812 - val_top_3_accuracy: 0.9361\n",
            "\n",
            "Epoch 00021: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 22/30\n",
            "902/902 [==============================] - 71s 79ms/step - loss: 0.3419 - categorical_accuracy: 0.8936 - top_2_accuracy: 0.9782 - top_3_accuracy: 0.9961 - val_loss: 0.9471 - val_categorical_accuracy: 0.6926 - val_top_2_accuracy: 0.8723 - val_top_3_accuracy: 0.9351\n",
            "\n",
            "Epoch 00022: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "Epoch 23/30\n",
            "902/902 [==============================] - 73s 81ms/step - loss: 0.3175 - categorical_accuracy: 0.8976 - top_2_accuracy: 0.9795 - top_3_accuracy: 0.9966 - val_loss: 0.9281 - val_categorical_accuracy: 0.7026 - val_top_2_accuracy: 0.8752 - val_top_3_accuracy: 0.9361\n",
            "\n",
            "Epoch 00023: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 24/30\n",
            "902/902 [==============================] - 73s 81ms/step - loss: 0.3234 - categorical_accuracy: 0.9031 - top_2_accuracy: 0.9817 - top_3_accuracy: 0.9978 - val_loss: 0.9372 - val_categorical_accuracy: 0.6926 - val_top_2_accuracy: 0.8752 - val_top_3_accuracy: 0.9391\n",
            "\n",
            "Epoch 00024: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "Epoch 25/30\n",
            "902/902 [==============================] - 72s 80ms/step - loss: 0.3086 - categorical_accuracy: 0.9043 - top_2_accuracy: 0.9814 - top_3_accuracy: 0.9982 - val_loss: 0.9173 - val_categorical_accuracy: 0.7166 - val_top_2_accuracy: 0.8822 - val_top_3_accuracy: 0.9361\n",
            "\n",
            "Epoch 00025: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 26/30\n",
            "902/902 [==============================] - 72s 79ms/step - loss: 0.3029 - categorical_accuracy: 0.9063 - top_2_accuracy: 0.9809 - top_3_accuracy: 0.9965 - val_loss: 0.9379 - val_categorical_accuracy: 0.7146 - val_top_2_accuracy: 0.8822 - val_top_3_accuracy: 0.9361\n",
            "\n",
            "Epoch 00026: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "Epoch 27/30\n",
            "902/902 [==============================] - 74s 82ms/step - loss: 0.2969 - categorical_accuracy: 0.9086 - top_2_accuracy: 0.9824 - top_3_accuracy: 0.9971 - val_loss: 0.9304 - val_categorical_accuracy: 0.7176 - val_top_2_accuracy: 0.8822 - val_top_3_accuracy: 0.9361\n",
            "\n",
            "Epoch 00027: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 28/30\n",
            "902/902 [==============================] - 76s 84ms/step - loss: 0.3159 - categorical_accuracy: 0.9020 - top_2_accuracy: 0.9820 - top_3_accuracy: 0.9969 - val_loss: 0.9256 - val_categorical_accuracy: 0.7126 - val_top_2_accuracy: 0.8822 - val_top_3_accuracy: 0.9361\n",
            "\n",
            "Epoch 00028: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
            "Epoch 29/30\n",
            "902/902 [==============================] - 75s 84ms/step - loss: 0.3071 - categorical_accuracy: 0.9073 - top_2_accuracy: 0.9813 - top_3_accuracy: 0.9978 - val_loss: 0.9324 - val_categorical_accuracy: 0.7086 - val_top_2_accuracy: 0.8802 - val_top_3_accuracy: 0.9351\n",
            "\n",
            "Epoch 00029: val_top_3_accuracy did not improve from 0.94711\n",
            "Epoch 30/30\n",
            "902/902 [==============================] - 75s 83ms/step - loss: 0.3081 - categorical_accuracy: 0.9035 - top_2_accuracy: 0.9787 - top_3_accuracy: 0.9961 - val_loss: 0.9310 - val_categorical_accuracy: 0.7106 - val_top_2_accuracy: 0.8822 - val_top_3_accuracy: 0.9351\n",
            "\n",
            "Epoch 00030: val_top_3_accuracy did not improve from 0.94711\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "val_loss: 0.9309658586873535\n",
            "val_cat_acc: 0.7105788410512986\n",
            "val_top_2_acc: 0.8822355274847168\n",
            "val_top_3_acc: 0.9351297384369635\n",
            "val_loss: 0.8390502612554503\n",
            "val_cat_acc: 0.7245508953631519\n",
            "val_top_2_acc: 0.871257483780741\n",
            "val_top_3_acc: 0.9471057883041823\n",
            "101/101 [==============================] - 13s 133ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[  7   2   3   1  11   9   0]\n",
            " [  4  20   0   3   4  19   1]\n",
            " [  5   2  26   2  24  51   0]\n",
            " [  2   1   0   6   0   3   0]\n",
            " [  3   0   3   4  29  72   0]\n",
            " [  2  11   6   5  17 628   2]\n",
            " [  0   0   1   0   0   3  10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMaZ6LITGmOr5BcAVPxA8gY4SAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elgqES7K9TKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZuduns9TM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjzdQQWx9TQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}